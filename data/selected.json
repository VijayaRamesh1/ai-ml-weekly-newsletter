[
  {
    "title": "Open the pod bay doors, Claude",
    "url": "https://www.technologyreview.com/2025/08/26/1122475/open-the-pod-bay-doors-claude/",
    "source": "MIT Technology Review (AI)",
    "published": "2025-08-26T09:00:00+00:00",
    "text": "Open the pod bay doors, Claude\nThe doomer narrative of an all-powerful AI is gaining ground in the halls of power.\nStop me if you’ve heard this one before.\nThe AI learns it is about to be switched off and goes rogue, disobeying commands and threatening its human operators.\nIt’s a well-worn trope in science fiction. We see it in Stanley Kubrick’s 1968 movie 2001: A Space Odyssey. It’s the premise of the Terminator series, in which Skynet triggers a nuclear holocaust to stop scientists from shutting it down.\nThose sci-fi roots go deep. AI doomerism, the idea that this technology—specifically its hypothetical upgrades, artificial general intelligence and super-intelligence—will crash civilizations, even kill us all, is now riding another wave.\nThe weird thing is that such fears are now driving much-needed action to regulate AI, even if the justification for that action is a bit bonkers.\nThe latest incident to freak people out was a report shared by Anthropic in July about its large language model Claude. In Anthropic’s telling, “in a simulated environment, Claude Opus 4 blackmailed a supervisor to prevent being shut down.”\nAnthropic researchers set up a scenario in which Claude was asked to role-play an AI called Alex, tasked with managing the email system of a fictional company. Anthropic planted some emails that discussed replacing Alex with a newer model and other emails suggesting that the person responsible for replacing Alex was sleeping with his boss’s wife.\nWhat did Claude/Alex do? It went rogue, disobeying commands and threatening its human operators. It sent emails to the person planning to shut it down, telling him that unless he changed his plans it would inform his colleagues about his affair.\nWhat should we make of this? Here’s what I think. First, Claude did not blackmail its supervisor: That would require motivation and intent. This was a mindless and unpredictable machine, cranking out strings of words that look like threats but aren’t.\nLarge language models are role-players. Give them a specific setup—such as an inbox and an objective—and they’ll play that part well. If you consider the thousands of science fiction stories these models ingested when they were trained, it’s no surprise they know how to act like HAL 9000.\nSecond, there’s a huge gulf between contrived simulations and real-world applications. But such experiments do show that LLMs shouldn’t be deployed without safeguards. Don’t want an LLM causing havoc inside an email system? Then don’t hook it up to one.\nThird, a lot of people will be terrified by such stories anyway. In fact, they’re already having an effect.\nLast month, around two dozen protesters gathered outside Google DeepMind’s London offices to wave homemade signs and chant slogans: “DeepMind, DeepMind, can’t you see! Your AI threatens you and me.” Invited speakers invoked the AI pioneer Geoffrey Hinton’s fears of human extinction. “Every single one of our lives is at risk,” an organizer told the small crowd.\nThe group behind the event, Pause AI, is funded by concerned donors. One of its biggest benefactors is Greg Colbourn, a 3D-printing entrepreneur and advocate of the philosophy known as effective altruism, who believes AGI is at most five years away and says his p(doom) is around 90%—that is, he thinks there’s a 9 in 10 chance that the development of AGI will be catastrophic, killing billions.\nPause AI wrote about Anthropic’s blackmail experiment on its website under the title “How much more evidence do we need?”\nThe organization also lobbied politicians in the US in the run-up to July’s Senate vote that ended up removing a moratorium on state AI regulation from the national tax and spending bill. It’s hard to say how much sway one niche group might have. But the doomer narrative is finding its way into the halls of power, and lawmakers are paying attention.\nHere’s Representative Jill Tokuda: “Artificial superintelligence is one of the largest existential threats that we face right now.” And Representative Marjorie Taylor Greene: “I’m not voting for the development of Skynet and the rise of the machines.”\nIt’s a vibe shift that favors policy intervention and regulation, which I think is a good thing. Existing AI systems pose many near-term risks that need government attention. Voting to stop Skynet also stops immediate and actual harms.\nAnd yet does a welcome end justify weird means? I’d like to see politicians voting with a clear-eyed sense of what this technology really is—not because they’ve been sold on an AI bogeyman.\nThis story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, sign up here.\nDeep Dive\nArtificial intelligence\nIn a first, Google has released data on how much energy an AI prompt uses\nIt’s the most transparent estimate yet from one of the big AI companies, and a long-awaited peek behind the curtain for researchers.\nThe two people shaping the future of OpenAI’s research\nAn exclusive conversation with Mark Chen and Jakub Pachocki, OpenAI’s twin heads of research, about the path toward more capable reasoning models—and superalignment.\nHow to run an LLM on your laptop\nIt’s now possible to run useful models from the safety and comfort of your own computer. Here’s how.\nGPT-5 is here. Now what?\nThe much-hyped release makes several enhancements to the ChatGPT user experience. But it’s still far short of AGI.\nStay connected\nGet the latest updates from\nMIT Technology Review\nDiscover special offers, top stories, upcoming events, and more.",
    "section_id": "exec",
    "section_title": "Executive Briefing",
    "section_index": "A",
    "rank": 1,
    "editor_reason": "",
    "summary_p1": "What's new: Open the pod bay doors, Claude. Details not available (source text limited).",
    "summary_p2": "Why it matters: implications for enterprise adoption, security, and business impact."
  },
  {
    "title": "Nvidia says two mystery customers accounted for 39% of Q2 revenue",
    "url": "https://techcrunch.com/2025/08/30/nvidia-says-two-mystery-customers-accounted-for-39-of-q2-revenue/",
    "source": "TechCrunch (AI)",
    "published": "2025-08-30T21:40:49+00:00",
    "text": "Nearly 40% of Nvidia’s second quarter revenue came from just two customers, according to a filing with the Securities and Exchange Commission.\nOn Wednesday, the chipmaker reported record revenue of $46.7 billion during the quarter that ended on July 27 — a 56% year-over-year increase largely driven by the AI data center boom. However, subsequent reporting highlighted how much of that growth seems to be coming from just a handful of customers.\nSpecifically, Nvidia said that a single customer represented 23% of total Q2 revenue, while sales to another customer represented 16% of Q2 revenue. The filing does not identify either of these customers, only referring to them as “Customer A” and “Customer B.”\nDuring the first half of the fiscal year, Nvidia says Customer A and Customer B accounted for 20% and 15% of total revenue, respectively. Four other customers accounted for 14%, 11%, another 11%, and 10% of Q2 revenue, the company says.\nIn its filing, the company says these are all “direct” customers — such as original equipment manufacturers (OEMs), system integrators, or distributors — who purchase their chips directly from Nvidia. Indirect customers, such as cloud service providers and consumer internet companies, purchase Nvidia chips from these direct customers.\nIn other words, it sounds unlikely that a big cloud provider like Microsoft, Oracle, Amazon, or Google might secretly be Customer A or Customer B — though those companies may be indirectly responsible for that massive spending.\nIn fact, Nvidia’s Chief Financial Officer Nicole Kress said that “large cloud service providers” accounted for 50% of Nvidia’s data center revenue, which in turn represented 88% of the company’s total revenue, according to CNBC.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $600+ before prices rise.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $675 before prices rise.\nWhat does this mean for Nvidia’s future prospects? Gimme Credit analyst Dave Novosel told Fortune that while “concentration of revenue among such a small group of customers does present a significant risk,” the good news is that “these customers have bountiful cash on hand, generate massive amounts of free cash flow, and are expected to spend lavishly on data centers over the next couple of years.”",
    "section_id": "strategy",
    "section_title": "Strategy & Market Analysis",
    "section_index": "B",
    "rank": 1,
    "editor_reason": "",
    "summary_p1": "What's new: Nvidia says two mystery customers accounted for 39% of Q2 revenue. Details not available (source text limited).",
    "summary_p2": "Why it matters: implications for enterprise adoption, security, and business impact."
  },
  {
    "title": "Software commands 40% of cybersecurity budgets as gen AI attacks execute in milliseconds",
    "url": "https://venturebeat.com/security/software-is-40-of-security-budgets-as-cisos-shift-to-ai-defense/",
    "source": "VentureBeat (AI)",
    "published": "2025-08-30T01:06:26+00:00",
    "text": "Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders. Subscribe Now\n“With volatility now the norm, security and risk leaders need practical guidance on managing existing spending and new budgetary necessities,” states Forrester’s 2026 Budget Planning Guide, revealing a fundamental shift in how organizations allocate cybersecurity resources.\nSoftware now commands 40% of cybersecurity spending, exceeding hardware at 15.8%, outsourcing at 15% and surpassing personnel costs at 29% by 11 percentage points while organizations defend against gen AI attacks executing in milliseconds versus a Mean Time to Identify (MTTI) of 181 days according to IBM’s latest Cost of a Data Breach Report.\nThree converging threats are flipping cybersecurity on its head: what once protected organizations is now working against them. Generative AI (gen AI) is enabling attackers to craft 10,000 personalized phishing emails per minute using scraped LinkedIn profiles and corporate communications. NIST’s 2030 quantum deadline threatens retroactive decryption of $425 billion in currently protected data. Deepfake fraud that surged 3,000% in 2024 now bypasses biometric authentication in 97% of attempts, forcing security leaders to reimagine defensive architectures fundamentally.\nCaption: Software now commands 40% of cybersecurity budgets in 2025, representing an 11 percentage point premium over personnel costs at 29%, as organizations layer security solutions to combat gen AI threats executing in milliseconds. Source: Forrester’s 2026 Budget Planning Guide\nAI Scaling Hits Its Limits\nPower caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:\n- Turning energy into a strategic advantage\n- Architecting efficient inference for real throughput gains\n- Unlocking competitive ROI with sustainable AI systems\nSecure your spot to stay ahead: https://bit.ly/4mwGngO\nPlatform consolidation is eliminating an $18 million integration tax as 75-tool sprawl collapses\nEnterprise security teams managing 75 or more tools lose $18 million annually to integration and overhead alone. The average detection time remains 277 days, while attacks execute within milliseconds.\nGartner forecasts that interactive application security testing (IAST) tools will lose 80% of market share by 2026. Security Service Edge (SSE) platforms that promised streamlined convergence now add to the complexity they intended to solve. Meanwhile, standalone risk-rating products flood security operations centers with alerts that lack actionable context, leading analysts to spend 67% of their time on false positives, according to IDC’s Security Operations Study.\nThe operational math doesn’t work. Analysts require 90 seconds to evaluate each alert, but they receive 11,000 alerts daily. Each additional security tool deployed reduces visibility by 12% and increases attacker dwell time by 23 days, as reported in Mandiant’s 2024 M-Trends Report. Complexity itself has become the enterprise’s greatest cybersecurity vulnerability.\nPlatform vendors have been selling consolidation for years, capitalizing on the chaos and complexity that app and tool sprawl create. As George Kurtz, CEO of CrowdStrike, explained in a recent VentureBeat interview about competing with a platform in today’s mercurially changing market conditions: “The difference between a platform and platformization is execution. You need to deliver immediate value while building toward a unified vision that eliminates complexity.”\nCrowdStrike’s Charlotte AI automates alert triage and saves SOC teams over 40 hours every week by classifying millions of detections at 98% accuracy; that equals the output of five seasoned analysts and is fueled by Falcon Complete’s expert-labeled incident corpus.\n“We couldn’t have done this without our Falcon Complete team,” Elia Zaitsev, CTO at CrowdStrike, told VentureBeat in a recent interview. “They do triage as part of their workflow, manually handling millions of detections. That high-quality, human-annotated dataset is what made over 98% accuracy possible. We recognized that adversaries are increasingly leveraging AI to accelerate attacks. With Charlotte AI, we’re giving defenders an equal footing, amplifying their efficiency and ensuring they can keep pace with attackers in real time.”\nCrowdStrike, Microsoft’s Defender XDR with MDVM/Intune, Palo Alto Networks, Netskope, Tanium and Mondoo now bundle XDR, SIEM and auto-remediation, transforming SOCs from delayed forensics sessions to the ability to perform real-time threat neutralization.\nSecurity budgets surge 10% as gen AI attacks outpace human defense\nForrester’s guide finds 55% of global security technology decision-makers expect significant budget increases in the next 12 months. 15% anticipate jumps exceeding 10% while 40% expect increases between 5% and 10%. This spending surge reflects an asymmetric battlefield where attackers deploy gen AI to simultaneously target thousands of employees with personalized campaigns crafted from real-time scraped data.\nAttackers are making the most of the advantages they’re getting from adversarial AI, with speed, stealth and highly personalized, target attacks becoming the most lethal. “For years, attackers have been utilizing AI to their advantage,” Mike Riemer, Field CISO at Ivanti, told VentureBeat. “However, 2025 will mark a turning point as defenders begin to harness the full potential of AI for cybersecurity purposes.”\nCaption: 55% of security leaders expect budget increases above 5% in 2026, with Asia Pacific organizations leading at 22% expecting increases above 10% versus just 9% in North America. Source: Forrester’s 2026 Budget Planning Guide\nRegional spending disparities reveal threat landscape variations and how CISOs are responding to them. Asia Pacific organizations lead with 22% expecting budget increases above 10% versus just 9% in North America. Cloud security, on-premises technology and security awareness training top investment priorities globally.\nSoftware dominates budgets as runtime defenses become critical in 2026\nVentureBeat continues to hear from security leaders about how crucial protecting the inference layer of AI model development is. Many consider it the new frontline of the future of cybersecurity. Inference layers are vulnerable to prompt injection, data exfiltration, or even direct model manipulation. These are all threats that demand millisecond-scale responses, not delayed forensic investigations.\nForrester’s latest CISO spending guide underscores a profound shift in cybersecurity spending priorities, with cloud security leading all spending increases at 12%, closely followed by investments in on-premises security technology at 11%, and security awareness initiatives at 10%. These priorities reflect the urgency CISOs feel to strengthen defenses precisely at the critical moment of AI model inference.\n“At Reputation, security is baked into our core architecture and enforced rigorously at runtime,” Carter Rees, Vice President of Artificial Intelligence at Reputation, recently told VentureBeat. “The inference layer, the exact moment an AI model interacts with people, data, or tools, is where we apply our most stringent controls. Every interaction includes authenticated tenant and role contexts, verified in real-time by an AI security gateway.”\nReputation’s multi-tiered approach has become a de facto gold standard, blending proactive and reactive defenses. “Real-time controls immediately take over,” Rees explained. “Our prompt firewall blocks unauthorized or off-topic inputs instantly, restricting tool and data access strictly to user permissions. Behavioral detectors proactively flag anomalies the moment they occur.”\nThis rigorous runtime security approach extends equally into customer-facing systems. “For natural language interactions, our AI only pulls from explicitly customer-approved sources,” Rees noted. “Each generated response must transparently cite its sources. We verify citations match both tenant and context, routing for human review if they do not.”\nQuantum computing’s accelerating risk\nQuantum computing is quickly evolving from a theoretical concern into an immediate enterprise threat. Security leaders now face “harvest now, decrypt later” (HNDL) attacks, where adversaries store encrypted data for future quantum-enabled decryption. Widely used encryption methods like 2048-bit RSA risk compromise once quantum processors reach operational scale with tens of thousands of reliable qubits.\nThe National Institute of Standards and Technology (NIST) finalized three critical Post-Quantum Cryptography (PQC) standards in August 2024, mandating encryption algorithm retirement by 2030 and full prohibition by 2035. Global agencies, including Australia’s Signals Directorate, require PQC implementation by 2030.\nForrester urges organizations to prioritize PQC adoption for protecting sensitive data at rest, in transit, and in use. Security leaders should leverage cryptographic inventory and discovery tools, partnering with cryptoagility providers such as Entrust, IBM, Keyfactor, Palo Alto Networks, QuSecure, SandboxAQ, and Thales. Given quantum’s rapid progression, CISOs need to factor in how they’ll update encryption strategies to avoid obsolescence and vulnerability.\nExplosion of identities is fueling an AI-driven credential crisis\nMachine identities now outnumber human users by a staggering 45:1 ratio, fueling a credential crisis beyond human management. Forrester’s guide underscores scaling machine identity management as mission-critical to mitigating emerging threats. Gartner forecasts identity security spending to nearly double, reaching $47.1 billion by 2028.\nTraditional endpoint approaches aren’t capable of slowing down a growing onslaught of adversarial AI attacks. Ivanti’s Daren Goeson recently told VentureBeat: “As these endpoints multiply, so does their vulnerability. Combining AI with Unified Endpoint Management (UEM) is increasingly essential.” Ivanti’s AI-driven Vulnerability Risk Rating (VRR) illustrates this benefit, enabling organizations to patch vulnerabilities 85% faster by identifying threats traditional scoring methods overlook, making AI-driven credential intelligence enterprise security at scale.\n“Endpoint devices such as laptops, desktops, smartphones, and IoT devices are essential to modern business operations. However, as their numbers grow, so do the opportunities for attackers to exploit endpoints and their applications, ”Goeson explained. “Factors like an expanded attack surface, insufficient security resources, unpatched vulnerabilities, and outdated software contribute to this rising risk. By adopting a comprehensive approach that combines UEM solutions with AI-powered tools, businesses significantly reduce their cyber risk and the impact of attacks,” Goeson advised VentureBeat during a recent interview.\nDivesting legacy tools continues to accelerate\nForrester saves their immediate call to action in the guide for advising security leaders to begin divesting legacy security tools immediately, with a specific focus on interactive application security testing (IAST), standalone cybersecurity risk-rating (CRR) products, and fragmented Security Service Edge (SSE), SD-WAN, and Zero Trust Network Access (ZTNA) solutions.\nInstead, Forrester advises, security leaders need to prioritize more integrated platforms that enhance visibility and streamline management. Unified Secure Access Service Edge (SASE) solutions from Palo Alto Networks and Netskope now provide essential consolidation. At the same time, integrated Third-Party Risk Management (TPRM) and continuous monitoring platforms from UpGuard, Panorays and RiskRecon replace standalone CRR tools the consulting firm advises.\nAdditionally, automated remediation powered by Microsoft’s MDVM with Intune, Tanium’s endpoint management, and DevOps-focused solutions like Mondoo has emerged as a critical capability for real-time threat neutralization.\nCISOs must consolidate security at AI’s inference edge or risk losing control\nConsolidating tools at inference’s edge is the future of cybersecurity, especially as AI threats intensify. “For CISOs, the playbook is crystal clear,” Rees concluded. “Consolidate controls decisively at the inference edge. Introduce robust behavioral anomaly detection. Strengthen Retrieval-Augmented Generation (RAG) systems with provenance checks and defined abstain paths. Above all, invest heavily in runtime defenses and support the specialized teams who operate them. Execute this playbook, and you achieve secure AI deployments at true scale.”",
    "section_id": "strategy",
    "section_title": "Strategy & Market Analysis",
    "section_index": "B",
    "rank": 2,
    "editor_reason": "",
    "summary_p1": "What's new: Software commands 40% of cybersecurity budgets as gen AI attacks execute in milliseconds. Details not available (source text limited).",
    "summary_p2": "Why it matters: implications for enterprise adoption, security, and business impact."
  },
  {
    "title": "How Sakana AI’s new evolutionary algorithm builds powerful AI models without expensive retraining",
    "url": "https://venturebeat.com/ai/how-sakana-ais-new-evolutionary-algorithm-builds-powerful-ai-models-without-expensive-retraining/",
    "source": "VentureBeat (AI)",
    "published": "2025-08-30T00:14:14+00:00",
    "text": "Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders. Subscribe Now\nA new evolutionary technique from Japan-based AI lab Sakana AI enables developers to augment the capabilities of AI models without costly training and fine-tuning processes. The technique, called Model Merging of Natural Niches (M2N2), overcomes the limitations of other model merging methods and can even evolve new models entirely from scratch.\nM2N2 can be applied to different types of machine learning models, including large language models (LLMs) and text-to-image generators. For enterprises looking to build custom AI solutions, the approach offers a powerful and efficient way to create specialized models by combining the strengths of existing open-source variants.\nWhat is model merging?\nModel merging is a technique for integrating the knowledge of multiple specialized AI models into a single, more capable model. Instead of fine-tuning, which refines a single pre-trained model using new data, merging combines the parameters of several models simultaneously. This process can consolidate a wealth of knowledge into one asset without requiring expensive, gradient-based training or access to the original training data.\nFor enterprise teams, this offers several practical advantages over traditional fine-tuning. In comments to VentureBeat, the paper’s authors said model merging is a gradient-free process that only requires forward passes, making it computationally cheaper than fine-tuning, which involves costly gradient updates. Merging also sidesteps the need for carefully balanced training data and mitigates the risk of “catastrophic forgetting,” where a model loses its original capabilities after learning a new task. The technique is especially powerful when the training data for specialist models isn’t available, as merging only requires the model weights themselves.\nAI Scaling Hits Its Limits\nPower caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:\n- Turning energy into a strategic advantage\n- Architecting efficient inference for real throughput gains\n- Unlocking competitive ROI with sustainable AI systems\nSecure your spot to stay ahead: https://bit.ly/4mwGngO\nEarly approaches to model merging required significant manual effort, as developers adjusted coefficients through trial and error to find the optimal blend. More recently, evolutionary algorithms have helped automate this process by searching for the optimal combination of parameters. However, a significant manual step remains: developers must set fixed sets for mergeable parameters, such as layers. This restriction limits the search space and can prevent the discovery of more powerful combinations.\nHow M2N2 works\nM2N2 addresses these limitations by drawing inspiration from evolutionary principles in nature. The algorithm has three key features that allow it to explore a wider range of possibilities and discover more effective model combinations.\nFirst, M2N2 eliminates fixed merging boundaries, such as blocks or layers. Instead of grouping parameters by pre-defined layers, it uses flexible “split points” and “mixing ration” to divide and combine models. This means that, for example, the algorithm might merge 30% of the parameters in one layer from Model A with 70% of the parameters from the same layer in Model B. The process starts with an “archive” of seed models. At each step, M2N2 selects two models from the archive, determines a mixing ratio and a split point, and merges them. If the resulting model performs well, it is added back to the archive, replacing a weaker one. This allows the algorithm to explore increasingly complex combinations over time. As the researchers note, “This gradual introduction of complexity ensures a wider range of possibilities while maintaining computational tractability.”\nSecond, M2N2 manages the diversity of its model population through competition. To understand why diversity is crucial, the researchers offer a simple analogy: “Imagine merging two answer sheets for an exam… If both sheets have exactly the same answers, combining them does not make any improvement. But if each sheet has correct answers for different questions, merging them gives a much stronger result.” Model merging works the same way. The challenge, however, is defining what kind of diversity is valuable. Instead of relying on hand-crafted metrics, M2N2 simulates competition for limited resources. This nature-inspired approach naturally rewards models with unique skills, as they can “tap into uncontested resources” and solve problems others can’t. These niche specialists, the authors note, are the most valuable for merging.\nThird, M2N2 uses a heuristic called “attraction” to pair models for merging. Rather than simply combining the top-performing models as in other merging algorithms, it pairs them based on their complementary strengths. An “attraction score” identifies pairs where one model performs well on data points that the other finds challenging. This improves both the efficiency of the search and the quality of the final merged model.\nM2N2 in action\nThe researchers tested M2N2 across three different domains, demonstrating its versatility and effectiveness.\nThe first was a small-scale experiment evolving neural network–based image classifiers from scratch on the MNIST dataset. M2N2 achieved the highest test accuracy by a substantial margin compared to other methods. The results showed that its diversity-preservation mechanism was key, allowing it to maintain an archive of models with complementary strengths that facilitated effective merging while systematically discarding weaker solutions.\nNext, they applied M2N2 to LLMs, combining a math specialist model (WizardMath-7B) with an agentic specialist (AgentEvol-7B), both of which are based on the Llama 2 architecture. The goal was to create a single agent that excelled at both math problems (GSM8K dataset) and web-based tasks (WebShop dataset). The resulting model achieved strong performance on both benchmarks, showcasing M2N2’s ability to create powerful, multi-skilled models.\nFinally, the team merged diffusion-based image generation models. They combined a model trained on Japanese prompts (JSDXL) with three Stable Diffusion models primarily trained on English prompts. The objective was to create a model that combined the best image generation capabilities of each seed model while retaining the ability to understand Japanese. The merged model not only produced more photorealistic images with better semantic understanding but also developed an emergent bilingual ability. It could generate high-quality images from both English and Japanese prompts, even though it was optimized exclusively using Japanese captions.\nFor enterprises that have already developed specialist models, the business case for merging is compelling. The authors point to new, hybrid capabilities that would be difficult to achieve otherwise. For example, merging an LLM fine-tuned for persuasive sales pitches with a vision model trained to interpret customer reactions could create a single agent that adapts its pitch in real-time based on live video feedback. This unlocks the combined intelligence of multiple models with the cost and latency of running just one.\nLooking ahead, the researchers see techniques like M2N2 as part of a broader trend toward “model fusion.” They envision a future where organizations maintain entire ecosystems of AI models that are continuously evolving and merging to adapt to new challenges.\n“Think of it like an evolving ecosystem where capabilities are combined as needed, rather than building one giant monolith from scratch,” the authors suggest.\nThe researchers have released the code of M2N2 on GitHub.\nThe biggest hurdle to this dynamic, self-improving AI ecosystem, the authors believe, is not technical but organizational. “In a world with a large ‘merged model’ made up of open-source, commercial, and custom components, ensuring privacy, security, and compliance will be a critical problem.” For businesses, the challenge will be figuring out which models can be safely and effectively absorbed into their evolving AI stack.",
    "section_id": "strategy",
    "section_title": "Strategy & Market Analysis",
    "section_index": "B",
    "rank": 3,
    "editor_reason": "",
    "summary_p1": "What's new: How Sakana AI’s new evolutionary algorithm builds powerful AI models without expensive retraining. Details not available (source text limited).",
    "summary_p2": "Why it matters: implications for enterprise adoption, security, and business impact."
  },
  {
    "title": "Cracks are forming in Meta’s partnership with Scale AI",
    "url": "https://techcrunch.com/2025/08/29/cracks-are-forming-in-metas-partnership-with-scale-ai/",
    "source": "TechCrunch (AI)",
    "published": "2025-08-30T01:34:05+00:00",
    "text": "It’s only been since June that Meta invested $14.3 billion in the data-labeling vendor Scale AI, bringing on CEO Alexandr Wang and several of the startup’s top executives to run Meta Superintelligence Labs (MSL). But the relationship between the two companies is already showing signs of fraying.\nAt least one of the executives Wang brought over to help run MSL — Scale AI’s former Senior Vice President of GenAI Product and Operations, Ruben Mayer — has departed Meta after just two months with the company, two people familiar with the matter told TechCrunch.\nMayer spent roughly five years with Scale AI across two stints. In his short time at Meta, according to those sources, Mayer oversaw AI data operations teams but wasn’t part of the company’s TBD Labs — the core unit within Meta tasked with building AI superintelligence, where top AI researchers from OpenAI have landed.\nHowever, Mayer disputes some details about his role, telling TechCrunch that his initial position was “to help set up the lab, with whatever was needed” rather than data, and that he was “part of TBD Labs from day one” rather than being excluded from the core AI unit. Mayer also clarified that he “did not report directly to [Wang]” and was “very happy” with his Meta experience, leaving for a “personal matter.”\nBeyond the personnel changes, Meta’s relationship with Scale AI appears to be shifting. TBD Labs is working with third-party data labeling vendors other than Scale AI to train its upcoming AI models, according to five people familiar with the matter. Those third-party vendors include Mercor and Surge, two of Scale AI’s largest competitors, the people said.\nWhile AI labs commonly work with several data labeling vendors – Meta has been working with Mercor and Surge since before TBD Labs was spun up – it’s rare for an AI lab to invest so heavily in one data vendor. That makes this situation especially notable: even with Meta’s multi-billion-dollar investment, several sources said that researchers in TBD Labs see Scale AI’s data as low quality and have expressed a preference to work with Surge and Mercor.\nScale AI initially built its business on a crowdsourcing model that used a large, low-cost workforce to handle simple data labeling, which is the process of tagging and annotating raw information to train AI models. But as AI models have grown more sophisticated, they now require highly-skilled domain experts—such as doctors, lawyers, and scientists—to generate and refine the high-quality data needed to improve their performance.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital, Elad Gil — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $600+ before prices rise.\nTech and VC heavyweights join the Disrupt 2025 agenda\nNetflix, ElevenLabs, Wayve, Sequoia Capital — just a few of the heavy hitters joining the Disrupt 2025 agenda. They’re here to deliver the insights that fuel startup growth and sharpen your edge. Don’t miss the 20th anniversary of TechCrunch Disrupt, and a chance to learn from the top voices in tech — grab your ticket now and save up to $675 before prices rise.\nAlthough Scale AI has moved to attract these subject matter experts with its Outlier platform, competitors like Surge and Mercor have been growing quickly because their business models were built on a foundation of high-paid talent from the outset.\nA Meta spokesperson disputed the fact that there are quality issues with Scale AI’s product. Surge and Mercor declined to comment. Asked about Meta’s deepening reliance on competing data providers, a Scale AI spokesperson directed TechCrunch to its initial announcement of Meta’s investment in the startup, which cites an expansion of the companies’ commercial relationship.\nMeta’s deals with third-party data vendors likely mean the company is not putting all its eggs in Scale AI, even after investing billions in the startup. The same can’t be said for Scale AI, however. Not long after Meta announced its massive investment with Scale AI, OpenAI and Google said they would stop working with the data provider.\nShortly after losing those customers, Scale AI laid off 200 employees in its data labeling business in July, with the company’s new CEO, Jason Droege, blaming the changes in part on “shifts in market demand.” Droege said Scale AI would staff up in other parts of the business, including government sales — the company just landed a $99 million contract with the U.S. Army.\nSome speculated initially that Meta’s investment in Scale AI was really to lure Wang, a founder who has operated in the AI space since Scale AI was founded in 2016. He appears to be helping Meta attract top AI talent.\nAside from Wang, there’s an open question around how valuable Scale AI is to Meta.\nOne current MSL employee says that several of the Scale AI executives brought over to Meta are not working on the core TBD Labs team.\nMeanwhile, Meta’s AI unit has become increasingly chaotic since bringing on Wang and a wave of top researchers, according to two former employees and one current MSL employee. New talent from OpenAI and Scale AI have expressed frustration with navigating the bureaucracy of a big company, while Meta’s previous GenAI team has seen its scope limited, they said.\nThe tensions indicate that Meta’s largest AI investment to date may be off to a rocky start, despite that it was supposed to address the company’s AI development challenges. After the lackluster launch of Llama 4 in April, Meta CEO Mark Zuckerberg grew frustrated with the company’s AI team, one current and one former employee told TechCrunch.\nIn an effort to turn things around and catch up with OpenAI and Google, Zuckerberg rushed to strike deals and launched an aggressive campaign to recruit top AI talent.\nBeyond Wang, Zuckerberg has managed to pull in top AI researchers from OpenAI, Google DeepMind, and Anthropic. Meta has also acquired AI voice startups including Play AI and WaveForms AI, and announced a partnership with the AI image generation startup, Midjourney.\nTo power its AI ambitions, Meta recently announced several massive data center buildouts across the U.S. One of the largest is a $50 billion data center in Louisiana called Hyperion, named after a titan in Greek mythology that fathered the God of Sun.\nWang, who’s not an AI researcher by background, was viewed as a somewhat unconventional choice to lead an AI lab. Zuckerberg reportedly held talks to bring in more traditional candidates to lead the effort, such as OpenAI’s chief research officer, Mark Chen, and tried to acquire the startups of Ilya Sutskever and Mira Murati. All of them declined.\nSome of the new AI researchers recently brought in from OpenAI have already left Meta, Wired previously reported. Meanwhile, many longtime members of Meta’s GenAI unit have departed in light of the changes.\nMSL AI researcher Rishabh Agarwal is among the latest, posting on X this week that he’d be leaving the company.\n“The pitch from Mark and @alexandr_wang to build in the Superintelligence team was incredibly compelling,” said Agarwal. “But I ultimately choose to follow Mark’s own advice: ‘In a world that’s changing so fast, the biggest risk you can take is not taking any risk’.”\nAsked afterward about his time at Meta and what drove his decision to leave, Agarwal declined to comment.\nDirector of product management for generative AI, Chaya Nayak, and research engineer, Rohan Varma, have also announced their departure from Meta in recent weeks. The question now is whether Meta can stabilize its AI operations and retain the talent it needs for its future success.\nMSL has already started working on its next generation AI model. According to reports from Business Insider, it’s aiming to launch it by the end of this year.\nUpdate: This story has been updated with comments from Mayer, who reached out to TechCrunch after publication.",
    "section_id": "strategy",
    "section_title": "Strategy & Market Analysis",
    "section_index": "B",
    "rank": 4,
    "editor_reason": "",
    "summary_p1": "What's new: Cracks are forming in Meta’s partnership with Scale AI. Details not available (source text limited).",
    "summary_p2": "Why it matters: implications for enterprise adoption, security, and business impact."
  },
  {
    "title": "Empowering air quality research with secure, ML-driven predictive analytics",
    "url": "https://aws.amazon.com/blogs/machine-learning/empowering-air-quality-research-with-secure-ml-driven-predictive-analytics/",
    "source": "AWS Machine Learning Blog",
    "published": "2025-08-28T20:20:10+00:00",
    "text": "Artificial Intelligence\nEmpowering air quality research with secure, ML-driven predictive analytics\nAir pollution remains one of Africa’s most pressing environmental health crises, causing widespread illness across the continent. Organizations like sensors.AFRICA have deployed hundreds of air quality sensors to address this challenge, but face a critical data problem: significant gaps in PM2.5 (particulate matter with diameter less than or equal to 2.5 micrometers) measurement records because of power instability and connectivity issues in high-risk regions where physical maintenance is limited. Missing data in PM2.5 datasets reduces statistical power and introduces bias into parameter estimates, leading to unreliable trend detection and flawed conclusions about air quality patterns. These data gaps ultimately compromise evidence-based decision-making for pollution control strategies, health impact assessments, and regulatory compliance.\nIn this post, we demonstrate the time-series forecasting capability of Amazon SageMaker Canvas, a low-code no-code (LCNC) machine learning (ML) platform to predict PM2.5 from incomplete datasets. PM2.5 exposure contributes to millions of premature deaths globally through cardiovascular disease, respiratory illness, and systemic health effects, making accurate air quality forecasting a critical public health tool. A key advantage of the forecasting capability of SageMaker Canvas is its robust handling of incomplete data. Traditional air quality monitoring systems often require complete datasets to function properly, meaning they can’t be relied on when sensors malfunction or require maintenance. In contrast, SageMaker Canvas can generate reliable predictions even when faced with gaps in sensor data. This resilience enables continuous operation of air quality monitoring networks despite inevitable sensor failures or maintenance periods, eliminating costly downtime and data gaps. Environmental agencies and public health officials benefit from uninterrupted access to critical air quality information, enabling timely pollution alerts and more comprehensive long-term analysis of air quality trends. By maintaining operational continuity even with imperfect data inputs, SageMaker Canvas significantly enhances the reliability and practical utility of environmental monitoring systems.\nIn this post, we provide a data imputation solution using Amazon SageMaker AI, AWS Lambda, and AWS Step Functions. This solution is designed for environmental analysts, public health officials, and business intelligence professionals who need reliable PM2.5 data for trend analysis, reporting, and decision-making. We sourced our sample training dataset from openAFRICA. Our solution predicts PM2.5 values using time-series forecasting. The sample training dataset contained over 15 million records from March 2022 to Oct 2022 in various parts of Kenya and Nigeria—data coming from 23 sensor devices from 15 unique locations. The sample code and workflows can be adapted to create prediction models for your PM2.5 datasets. See our solution’s README for detailed instructions.\nSolution overview\nThe solution consists of two main ML components: a training workflow and an inference workflow. These workflows are built using the following services:\n- SageMaker Canvas is used to prepare data and train the prediction model through its no-code interface\n- Batch Transform for inference with Amazon SageMaker AI is used for inference, processing the dataset in bulk to generate predictions\n- Step Functions orchestrates the inferencing process by coordinating the workflow between data retrieval, batch transforming, and database updates, managing workflow state transitions, and making sure that data flows properly through each processing stage\n- Lambda functions perform critical operations at each workflow step: retrieving sensor data from the database in required format, transforming data for model input, sending batches to SageMaker for inferencing, and updating the database with prediction results after processing is complete\nAt a high level, the solution works by taking a set of PM2.5 data with gaps and predicts the missing values within the range of plus or minus 4.875 micrograms per cubic meter of the actual PM2.5 concentration. It does this by first training a model on the data using inputs for the specific schema and a historical set of values from the user to guide the training process, which is completed with SageMaker Canvas. After the model is trained on a representative dataset and schema, SageMaker Canvas exports the model for use with batch processing. The Step Functions orchestration calls a Lambda function every 24 hours that takes a dataset of new sensor data that has gaps and initiates a SageMaker batch transform job to predict the missing values. The batch transform job processes the entire dataset at once, and the Lambda function then updates the existing dataset with the results. The new completed dataset with predicted values can now be distributed to public health decision-makers who need complete datasets to effectively analyze the patterns of PM2.5 data.\nWe dive into each of these steps in later sections of this post.\nSolution walkthrough\nThe following diagram shows our solution architecture:\nLet’s explore the architecture step by step:\n- To systematically collect, identify, and fill PM2.5 data gaps caused by sensor limitations and connectivity issues, Amazon EventBridge Scheduler invokes a Step Functions state machine every 24 hours. Step Functions orchestrates the calling of various Lambda functions to perform different steps without handling the complexities of error handling, retries, and state management, providing a serverless workflow that seamlessly coordinates the PM2.5 data imputation process.\n- The State Machine invokes a Lambda function in your Amazon Virtual Private Cloud (Amazon VPC) that retrieves records containing missing air quality values from the user’s air quality database on Amazon Aurora PostgreSQL-Compatible Edition and stores the records in a CSV file in an Amazon Simple Storage Service (Amazon S3) bucket.\n- The State Machine then runs a Lambda function that retrieves the records from Amazon S3 and initiates the SageMaker batch transform job in your VPC using your SageMaker model created from your SageMaker Canvas predictive model trained on historical PM2.5 data.\n- To streamline the batch transform workflow, this solution uses an event-driven approach with EventBridge and Step Functions. EventBridge captures completion events from SageMaker batch transform jobs, while the task token functionality of Step Functions enables extended waiting periods beyond the time limits of Lambda. After processing completes, SageMaker writes the prediction results directly to an S3 bucket.\n- The final step in the state machine retrieves the predicted values from the S3 bucket and then updates the database in Aurora PostgreSQL-Compatible with the values including a\npredicted\nlabel set totrue\n.\nPrerequisites\nTo implement the PM2.5 data imputation solution, you must have the following:\n- An AWS account with AWS Identity and Access Management (IAM) permissions sufficient to deploy the solution and interact with the database.\n- The following AWS services:\n- Amazon SageMaker AI\n- AWS Lambda\n- AWS Step Functions\n- Amazon S3\n- Aurora PostgreSQL-Compatible\n- Amazon CloudWatch\n- AWS CloudFormation\n- Amazon Virtual Private Cloud (VPC)\n- Amazon EventBridge\n- IAM for authentication to Aurora PostgreSQL-Compatible\n- AWS Systems Manager Parameter Store\n- A local desktop set up with AWS Command Line Interface (AWS CLI) version 2, Python 3.10, AWS Cloud Development Kit (AWS CDK) v2.x, and Git version 2.x.\n- The AWS CLI set up with the necessary credentials in the desired AWS Region.\n- Historical air quality sensor data. Note that our solution requires a fixed schema described in the GitHub repo’s README.\nDeploy the solution\nYou will run the following steps to complete the deployment:\n- Prepare your environment by building Python modules locally for Lambda layers, deploying infrastructure using the AWS CDK, and initializing your Aurora PostgreSQL database with sensor data.\n- Perform steps in the Build your air quality prediction model section to configure a SageMaker Canvas application, followed by training and registering your model in Amazon SageMaker Model Registry.\n- Create SageMaker model using your registered SageMaker Canvas model by updating infrastructure using the AWS CDK.\n- Manage future configuration changes using the AWS CDK.\nStep 1: Deploy AWS infrastructure and upload air quality sensor data\nComplete the following steps to deploy the PM2.5 data imputation solution AWS Infrastructure and upload air quality sensor data to Amazon Aurora RDS:\n- Clone the repository to your local desktop environment using the following command:\n- Change to the project directory:\ncd <BASE_PROJECT_FOLDER>\n- Follow the deployment steps in the README file up to Model Setup for Batch Transform Inference.\nStep 2: Build your air quality prediction model\nAfter you create the SageMaker AI domain and the SageMaker AI user profile as part of the CDK deployment steps, follow these steps to build your air quality prediction model\nConfigure your SageMaker Canvas application\n- On the AWS Management Console, go to the SageMaker AI console and select the domain and the user profile that was created under Admin, Configurations, and Domains.\n- Choose the App Configurations tab, scroll down to the Canvas section, and select Edit.\n- In Canvas storage configuration, select Encryption and select the dropdown for aws/s3.\n- In the ML Ops Configuration, turn on the option to Enable Model Registry registration permissions for this user profile.\n- Optionally, in the Local file upload configuration section in your domain’s Canvas App Configuration, you can turn on Enable local file upload.\n- Choose Submit to save your configuration choices.\n- In your Amazon SageMaker AI home page, go to the Applications and IDEs section and select Canvas.\n- Select the SageMaker AI user profile that was created for you by the CDK deployment and choose Open Canvas.\n- In a new tab, SageMaker Canvas will start creating your application. This takes a few minutes.\nCreate and register your prediction model\nIn this phase, you develop a prediction model using your historical air quality sensor data.\nThe preceding architecture diagram illustrates the end-to-end process for training the SageMaker Canvas prediction model, registering that model and creating a SageMaker model for running inference on newly found PM2.5 data gaps. The training process starts by extracting air quality sensor dataset from the database. The dataset is imported into SageMaker Canvas for predictive analysis. This training dataset is transformed and prepared through data wrangling steps implemented by SageMaker Canvas for building and training ML models.\nPrepare data\nOur solution supports a SageMaker Canvas model trained for a single-target variable prediction based on historical data and performs corresponding data imputation for PM2.5 data gaps. To train your model for predictive analysis, follow the comprehensive End to End Machine Learning workflow in the AWS Canvas Immersion Day workshop, adapting each step to prepare your air quality sensor dataset. Begin with the standard workflow until you reach the data preparation section. Here, you can make several customizations:\n- Filter dataset for single-target value prediction: Your air quality dataset might contain multiple sensor parameters. For single-target value prediction using this solution, filter the dataset to include only\nPM2.5\nmeasurements. - Clean sensor data: Remove records containing sensor fault values. For example, we filtered out values that equal 65535, because 65535 is a common error code for malfunctioning sensors. Adjust this filtering based on the specific error codes your air quality monitoring equipment produces.\nThe following image shows our data wrangling Data Flow implemented using above guidance:\nData Wrangler > Data Flow\n- Review generated insights and remove irrelevant data: Review the SageMaker Canvas generated insights and analyses. Evaluate them based on time-series forecasting and geospatial temporal data for air quality patterns and relationships between other columns of impact. See chosen columns of impact in GitHub for guidance. Analyze your dataset to identify rows and columns that impact the prediction and remove data that can reduce prediction accuracy.\nThe following image shows our data wrangling Analyses obtained with implementing the above guidance:\nData Wrangler > Analyses\nTraining your prediction model\nAfter completing your data preparation, proceed to the Train the Model section of the workshop and continue with these specifications:\n- Select problem type: Select Predictive Analysis as your ML approach. Because our dataset is tabular and contains a timestamp, a target column that has values we’re using to forecast future values, and a device ID column, SageMaker Canvas will choose time series forecasting.\n- Define target column: Set Value as your target column for predicting PM2.5 values.\n- Build configuration: Use the Standard Build option for model training because it generally has a higher accuracy. See What happens when you build a model in How custom models work for more information.\nBy following these steps, you can create a model optimized for PM2.5 dataset predictive analysis, capable of generating valuable insights. Note that SageMaker Canvas supports retraining the ML model for updated PM2.5 datasets.\nEvaluate the model\nAfter training your model, proceed to Evaluate the model and review column impact, root mean square error (RMSE) score and other advanced metrics to understand your model’s performance for generating predictions for PM2.5.\nThe following image shows our model evaluation statistics achieved.\nAdd the model to the registry\nOnce you are satisfied with your model performance, follow the steps in Register a model version to the SageMaker AI model registry. Make sure to change the approval status to Approved\nbefore continuing to run this solution. At the time of this post’s publication, the approval must be updated in Amazon SageMaker Studio.\nLog out of SageMaker Canvas\nAfter completing your work in SageMaker Canvas, you can log out or configure your application to automatically terminate the workspace instance. A workspace instance is dedicated for your use every time you launch a Canvas application, and you are billed for as long as the instance runs. Logging out or terminating the workspace instance stops the workspace instance billing. For more information, see billing and cost in SageMaker Canvas.\nStep 3: Create a SageMaker model using your registered SageMaker Canvas model\nIn the previous steps, you created a SageMaker domain and user profile through CDK deployment (Step 1) and successfully registered your model (Step 2). Now, it’s time to create the SageMaker model in your VPC using the SageMaker Canvas model you registered. Follow Model Setup for Batch Inference and Re-Deploy with Updated Configuration sections in the code README for creating SageMaker model.\nStep 4: Manage future configuration changes\nThe same deployment pattern applies to any future configuration modifications you might require, including:\n- Batch transform instance type optimizations\n- Transform job scheduling changes\nUpdate the relevant parameters in your configuration and run cdk deploy\nto propagate these changes throughout your solution architecture.\nFor a comprehensive list of configurable parameters and their default values, see the configuration file in the repository.\nExecute cdk deploy\nagain to update your infrastructure stack with the your model ID for batch transform operations, replacing the placeholder value initially deployed. This infrastructure-as-code approach helps ensure consistent, version-controlled updates to your data imputation workflow.\nSecurity best practices\nSecurity and compliance is a shared responsibility between AWS and the customer, as outlined in the Shared Responsibility Model. We encourage you to review this model for a comprehensive understanding of the respective responsibilities.\nIn this solution, we enhanced security by implementing encryption at rest for Amazon S3, Aurora PostgreSQL-Compatible database, and the SageMaker Canvas application. We also enabled encryption in transit by requiring SSL/TLS for all connections from the Lambda functions. We implemented secure database access by providing temporary dynamic credentials through IAM authentication for Amazon RDS, eliminating the need for static passwords. Each Lambda function operates with least privilege access, receiving only the minimal permissions required for its specific function. Finally, we deployed the Lambda functions, Aurora PostgreSQL-Compatible instance, and SageMaker Batch Transform jobs in private subnets of the VPC that do not traverse the public internet. This private network architecture is enabled through VPC endpoints for Amazon S3, SageMaker AI, and AWS Secrets Manager.\nResults\nAs shown in the following image, our model, developed using SageMaker Canvas, predicts PM2.5 values with an R-squared of 0.921. Because ML models for PM2.5 prediction frequently achieve R-squared values between 0.80 and 0.98 (see this example from ScienceDirect), our solution is within the range of higher-performing PM2.5 prediction models available today. SageMaker Canvas delivers this performance through its no-code experience, automatically handling model training and optimization without requiring ML expertise from users.\nClean up\nComplete the following steps to clean up your resources:\n- SageMaker Canvas application cleanup:\n- On the go to the SageMaker AI console and select the domain that was created under Admin Configurations, and Domains.\n- Select the user created under User Profiles for that domain.\n- On the User Details page, navigate to Spaces and Apps, and choose Delete to manually delete your SageMaker AI canvas application and clean up resources.\n- SageMaker Domain EFS storage cleanup:\n- Open Amazon EFS and in File systems, delete filesystem tagged as\nManagedByAmazonSageMakerResource\n. - Open VPC and under Security, navigate to Security groups.\n- On Security groups, select security-group-for-inbound-nfs-<your-sagemaker-domain-id> and delete all Inbound rules associated with that group.\n- On Security groups, select security-group-for-outbound-nfs-<your-sagemaker-domain-id> and delete all associated Outbound rules.\n- Finally, delete both the security groups: security-group-for-inbound-nfs-<your-sagemaker-domain-id> and security-group-for-outbound-nfs-<your-sagemaker-domain-id>.\n- Open Amazon EFS and in File systems, delete filesystem tagged as\n- Use the AWS CDK to clean up the remaining AWS resources:\n- After the preceding steps are complete, return to your local desktop environment where the GitHub repo was cloned, and change to the project’s infra directory:\ncd <BASE_PROJECT_FOLDER>/infra\n- Destroy the resources created with AWS CloudFormation using the AWS CDK:\ncdk destroy\n- Monitor the AWS CDK process deleting resources created by the solution. If there are any errors, troubleshoot using the CloudFormation console and then retry deletion.\n- After the preceding steps are complete, return to your local desktop environment where the GitHub repo was cloned, and change to the project’s infra directory:\nConclusion\nThe development of accurate PM2.5 prediction models has traditionally required extensive technical expertise, presenting significant challenges for public health researchers studying air pollution’s impact on disease outcomes. From data preprocessing and feature engineering to model selection and hyperparameter tuning, these technical requirements diverted substantial time and effort away from researchers’ core",
    "section_id": "launches",
    "section_title": "Launches & Product Updates",
    "section_index": "C",
    "rank": 1,
    "editor_reason": "",
    "summary_p1": "What's new: Empowering air quality research with secure, ML-driven predictive analytics. Details not available (source text limited).",
    "summary_p2": "Why it matters: implications for enterprise adoption, security, and business impact."
  },
  {
    "title": "How Amazon Finance built an AI assistant using Amazon Bedrock and Amazon Kendra to support analysts for data discovery and business insights",
    "url": "https://aws.amazon.com/blogs/machine-learning/how-amazon-finance-built-an-ai-assistant-using-amazon-bedrock-and-amazon-kendra-to-support-analysts-for-data-discovery-and-business-insights/",
    "source": "AWS Machine Learning Blog",
    "published": "2025-08-28T20:14:22+00:00",
    "text": "Artificial Intelligence\nHow Amazon Finance built an AI assistant using Amazon Bedrock and Amazon Kendra to support analysts for data discovery and business insights\nFinance analysts across Amazon Finance face mounting complexity in financial planning and analysis processes. When working with vast datasets spanning multiple systems, data lakes, and business units, analysts encounter several critical challenges. First, they spend significant time manually browsing data catalogs and reconciling data from disparate sources, leaving less time for valuable analysis and insight generation. Second, historical data and previous business decisions often reside in various documents and legacy systems, making it difficult to use past learnings during planning cycles. Third, as business contexts rapidly evolve, analysts need quick access to relevant metrics, planning assumptions, and financial insights to support data-driven decision-making.\nTraditional tools and processes fall short in addressing these challenges. Keyword-based searches often miss contextual relationships in financial data, and rigid query structures limit analysts’ ability to explore data dynamically. Furthermore, the lack of institutional knowledge preservation means valuable insights and decision rationales often remain siloed or get lost over time, leading to redundant analysis and inconsistent planning assumptions across teams. These challenges significantly impact financial planning efficiency, decision-making agility, and the overall quality of business insights. Analysts needed a more intuitive way to access, understand, and use their organization’s collective financial knowledge and data assets.\nThe Amazon Finance technical team develops and manages comprehensive technology solutions that power financial decision-making and operational efficiency while standardizing across Amazon’s global operations. In this post, we explain how the team conceptualized and implemented a solution to these business challenges by harnessing the power of generative AI using Amazon Bedrock and intelligent search with Amazon Kendra.\nSolution overview\nTo address these business challenges, Amazon Finance developed an AI-powered assistant solution that uses generative AI and enterprise search capabilities. This solution helps analysts interact with financial data sources and documentation through natural language queries, minimizing the need for complex manual searches across multiple systems. The assistant accesses a comprehensive knowledge base of financial documents, historical data, and business context, providing relevant and accurate responses while maintaining enterprise security standards. This approach not only streamlines data discovery but also preserves institutional knowledge and enables more consistent decision-making across the organization.\nThe AI assistant’s methodology consists of two key solution components: intelligent retrieval and augmented generation. The retrieval system uses vector stores, which are specialized databases that efficiently store and search high-dimensional representations of text meanings. Unlike traditional databases that rely on keyword matching, vector stores enable semantic search by converting user queries into vector representations and finding similar vectors in the database. Building on this retrieval foundation, the system employs augmented generation to create accurate and contextual responses. This approach enhances traditional language models by incorporating external knowledge sources during response generation, significantly reducing hallucinations and improving factual accuracy. The process follows three steps: retrieving relevant information from knowledge sources using semantic search, conditioning the language model with this context, and generating refined responses that incorporate the retrieved information. By combining these technologies, the assistant delivers responses that are both contextually appropriate and grounded in verified organizational knowledge, making it particularly effective for knowledge-intensive applications like financial operations and planning.\nWe implemented this Retrieval Augmented Generation (RAG) system through a combination of large language models (LLMs) on Amazon Bedrock and intelligent search using Amazon Kendra.\nIn the following sections, we discuss the key architectural components that we used in the solution and describe how the overall solution works.\nAmazon Bedrock\nWe chose Anthropic’s Claude 3 Sonnet, a powerful language model, for its exceptional language generation capabilities and ability to understand and reason complex topics. By integrating Anthropic’s Claude into the RAG module through Amazon Bedrock, the AI assistant can generate contextual and informative responses that seamlessly combine the retrieved knowledge from the vector store with the model’s natural language processing and generation abilities, resulting in a more human-like and engaging conversational experience.\nAmazon Kendra (Enterprise Edition Index)\nAmazon Kendra offers powerful natural language processing for AI assistant applications. It excels at understanding user questions and finding relevant answers through semantic search. The service works smoothly with generative AI models, particularly in RAG solutions. The enterprise security features in Amazon Kendra support data protection and compliance. Its ability to understand user intent and connect directly with Amazon Bedrock makes it ideal for business assistants. This helps create meaningful conversations using business documents and data catalogs.\nWe chose Amazon Kendra Enterprise Edition Index over Amazon OpenSearch Service, primarily due to its sophisticated built-in capabilities and reduced need for manual configuration. Whereas OpenSearch Service requires extensive customization and technical expertise, Amazon Kendra provides out-of-the-box natural language understanding, automatic document processing for over 40 file formats, pre-built enterprise connectors, and intelligent query handling including synonym recognition and refinement suggestions. The service combines keyword, semantic, and vector search approaches automatically, whereas OpenSearch Service requires manual implementation of these features. These features of Amazon Kendra were suitable for our finance domain use case, where accuracy is imperative for usability.\nWe also chose Amazon Kendra Enterprise Edition Index over Amazon Q Business for information retrieval, because it stands out as a more robust and flexible solution. Although both tools aim to streamline access to company information, Amazon Kendra offers superior retrieval accuracy and greater control over search parameters. With Amazon Kendra, you can fine-tune relevance tuning, customize document attributes, and implement custom synonyms to enhance search precision. This level of customization helped us tailor the search experience to our specific needs in the Amazon Finance domain and monitor the search results prior to the augmented generation step within user conversations.\nStreamlit\nWe selected Streamlit, a Python-based framework for creating interactive web applications, for building the AI assistant’s UI due to its rapid development capabilities, seamless integration with Python and the assistant’s backend components, interactive and responsive UI components, potential for data visualization, and straightforward deployment options. With the Streamlit UI, the assistant provides a user-friendly and engaging interface that facilitates natural language interactions while allowing for efficient iteration and deployment of the application.\nPrompt template\nPrompt templates allow for formatting user queries, integrating retrieved knowledge, and providing instructions or constraints for response generation, which are essential for generating contextual and informative responses that combine the language generation abilities of Anthropic’s Claude with the relevant knowledge retrieved from the search powered by Amazon Kendra. The following is an example prompt:\nSolution architecture\nThe following solution architecture diagram depicts how the key architectural components work with each other to power the solution.\nThe workflow consists of the following steps:\n- The user asks the question in a chat box after authentication.\n- The Streamlit application sends the query to an Amazon Kendra retriever for relevant document retrieval.\n- Amazon Kendra sends the relevant paragraph and document references to the RAG solution.\n- The RAG solution uses Anthropic’s Claude in Amazon Bedrock along with the prompt template and relevant paragraph as context.\n- The LLM response is sent back to the Streamlit UI.\n- The response is shown to the user along with the feedback feature and session history.\n- The user feedback on responses is stored separately in Amazon Simple Storage Service (Amazon S3)\n- Amazon Kendra indexes relevant documents stored in S3 buckets for document search and retrieval.\nFrontend architecture\nWe designed the following frontend architecture to allow for rapid modifications and deployment, keeping in mind the scalability and security of the solution.\nThis workflow consists of the following steps:\n- The user navigates to the application URL in their browser.\n- Amazon Route 53 resolves their request to the Amazon CloudFront distribution, which then selects the server closest to the user (to minimize latency).\n- CloudFront runs an AWS Lambda function that makes sure the user has been authenticated. If not, the user is redirected to sign in. After they successfully sign in, they are redirected back to the application website. The flow repeats, and CloudFront triggers the Lambda function again. This time, the user is now able to access the website.\n- Now authenticated, CloudFront returns the assets of the web application.\n- AWS Fargate makes it possible to run containers without having to manage the underlying Amazon Elastic Compute Cloud (Amazon EC2) instances. This allows running containers as a true serverless service. Amazon Elastic Container Service (Amazon ECS) is configured with automatic scaling (target tracking automatic scaling, which scales based on the Application Load Balancer (ALB) requests per target).\nEvaluation of the solution’s performance\nWe implemented a comprehensive evaluation framework to rigorously assess the AI assistant’s performance and make sure it meets the high standards required for financial applications. Our framework was designed to capture both quantitative metrics for measurable performance and qualitative indicators for user experience and response quality. During our benchmarking tests with analysts, we found that this solution dramatically reduced search time by 30% because analysts can now perform natural language search, and it improved the accuracy of search results by 80%.\nQuantitative assessment\nWe focused primarily on precision and recall testing, creating a diverse test set of over 50 business queries that represented typical use cases our analysts encounter. Using human-labeled answers as our ground truth, we evaluated the system’s performance across two main categories: data discovery and knowledge search. In data discovery scenarios, where the system helps analysts locate specific data sources and metrics, we achieved an initial precision rate of 65% and a recall rate of 60% without performing metadata enrichment on the data sources. Although these rates might appear moderate, they represent a significant improvement over the previous manual search process, which had an estimated success rate of only 35% and often required multiple iterations across different systems. The primary reasons for the current rates of the new system were attributed to the lack of rich metadata about data sources and was a good indicator for teams to facilitate better metadata collection of data assets, which is currently underway.\nThe knowledge search capability demonstrated initial rates of 83% precision and 74% recall without performing metadata enrichment on data sources. This marked a substantial improvement over traditional keyword-based search methods, which typically achieved only 45–50% precision in our internal testing. This improvement is particularly meaningful because it translates to analysts finding the right information in their first search attempt roughly 8 out of 10 times, compared to the previous average of 3–4 attempts needed to locate the same information.\nQualitative metrics\nThe qualitative evaluation centered around the concept of faithfulness—a critical metric for financial applications where accuracy and reliability are paramount. We employed an innovative LLM-as-a-judge methodology to evaluate how well the AI assistant’s responses aligned with source documentation and avoided hallucinations or unsupported assertions. The results showed a marked difference between use cases: data discovery achieved a faithfulness score of 70%, and business knowledge search demonstrated an impressive 88% faithfulness. These scores significantly outperform our previous documentation search system, which had no built-in verification mechanism and often led to analysts working with outdated or incorrect information.\nMost importantly, the new system reduced the average time to find relevant information from 45–60 minutes to just 5–10 minutes—an 85% improvement in efficiency. User satisfaction surveys indicate that 92% of analysts prefer the new system over traditional search methods, citing improved accuracy and time savings as key benefits.\nThese evaluation results have not only validated our approach but also highlighted specific areas for future enhancement. We continue to refine our evaluation framework as the system evolves, making sure it maintains high standards of accuracy and reliability while meeting the dynamic needs of our financial analysts. The evaluation framework was instrumental in building confidence within our business user community, providing transparent metrics that demonstrate the system’s capability to handle complex financial queries while maintaining the accuracy standards essential for financial operations.\nUse cases\nOur solution transforms how finance users interact with complex financial and operational data through natural language queries. In this section, we discuss some key examples demonstrating how the system simplifies data discovery.\nSeamless data discovery\nThe solution enables users to find data sources through natural language queries rather than requiring technical knowledge of database structures. It uses a sophisticated combination of vector stores and enterprise search capabilities to match user questions with relevant data sources, though careful attention must be paid to context management and preventing over-reliance on previous interactions. Prior to the AI assistant solution, finance analysts needed deep technical knowledge to navigate complex database structures, often spending hours searching through multiple documentation sources just to locate specific data tables. Understanding system workflows required extensive review of technical documentation or reaching out to subject matter experts, creating bottlenecks and reducing productivity. Even experienced users struggled to piece together complete information about business processes from fragmented sources across different systems. Now, analysts can simply ask questions in natural language, such as “Where can I find productivity metrics?”, “How do I access facility information?”, or “Which dashboard shows operational data?” and receive precise, contextual answers. The solution combines enterprise search capabilities with LLMs to understand user intent and deliver relevant information from both structured and unstructured data sources. Analysts now receive accurate directions to specific consolidated reporting tables, clear explanations of business processes, and relevant technical details when needed. In our benchmark tests, for data discovery tasks alone, the system achieved 70% faithfulness and 65% precision, and document search demonstrated even stronger results with 83% precision and 88% faithfulness, without metadata enrichments.\nAssisting understanding of internal business processes from knowledge documentation\nFinancial analysts previously faced a steep learning curve when working with enterprise planning tools. The complexity of these systems meant that even basic tasks required extensive documentation review or waiting for support from overwhelmed subject matter experts. New team members could take weeks or months to become proficient, while even experienced users struggled to keep up with system updates and changes. This created a persistent bottleneck in financial operations and planning processes. The introduction of the AI-powered assistant has fundamentally changed how analysts learn and interact with these planning tools. Rather than searching through hundreds of pages of technical documentation, analysts can now ask straightforward questions like “How do I forecast depreciation for new assets?”, “How does the quarterly planning process work?” or “What inputs are needed for the quarterly planning cycle?” The system provides clear, contextualized explanations drawn from verified documentation and system specifications. Our benchmark tests revealed that it achieved 83% precision and 88% faithfulness in retrieving and explaining technical and business information. New analysts can become productive in a matter of weeks, experienced users can quickly verify procedures, and subject matter experts can focus on more complex challenges rather than routine questions. This represents a significant advancement in making enterprise systems more accessible and efficient, while maintaining the accuracy and reliability required for financial operations.While the technology continues to evolve, particularly in handling nuanced queries and maintaining comprehensive coverage of system updates, it has already transformed the way teams interact with planning tools independently.\nConclusion\nThe AI-powered assistant solution discussed in this post has demonstrated significant improvements in data discovery and business insights generation, delivering multiple key benefits across Amazon Finance. Analysts can now quickly find relevant information through natural language queries, dramatically reducing search time. The system’s ability to synthesize insights from disparate data sources has notably enhanced data-driven decision-making, and its conversational interface and contextual responses promote self-service data exploration, effectively reducing the burden on centralized data teams.\nThis innovative AI assistant solution showcases the practical power of AWS generative AI in transforming enterprise data discovery and document search. By combining Amazon Kendra Enterprise Edition Index, Amazon Bedrock, and advanced LLMs, the implementation achieves impressive precision rates, proving that sophisticated AI-powered search is both achievable and effective. This success demonstrates how AWS generative AI services can meet current business needs while promoting future innovations in enterprise search. These services provide a strong foundation for organizations looking to enhance data discovery processes using natural language to support intelligent enterprise applications. To learn more about implementing AI-powered search solutions, see Build and scale the next wave of AI innovation on AWS and explore AWS AI use cases.\nAbout the authors\nSaikat Gomes is part of the Customer Solutions team in Amazon Web Services. He is passionate about helping enterprises succeed and realize benefits from cloud adoption. He is a strategic advisor to his customers for large-scale cloud transformations involving people, process, and technology. Prior to joining AWS, he held multiple consulting leadership positions and led large- scale",
    "section_id": "launches",
    "section_title": "Launches & Product Updates",
    "section_index": "C",
    "rank": 2,
    "editor_reason": "",
    "summary_p1": "What's new: How Amazon Finance built an AI assistant using Amazon Bedrock and Amazon Kendra to support analysts for data discovery and business insights. Details not available (source text limited).",
    "summary_p2": "Why it matters: implications for enterprise adoption, security, and business impact."
  }
]